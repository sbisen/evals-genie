# Real-Time Evaluation System with Gemini API

## Overview
The evaluation system now uses Google's Gemini API to perform real-time evaluation of test sets by comparing ground truth answers with agent-generated responses.

## How It Works

### 1. Evaluation Flow
When you click "Run Evaluation" in the frontend:

1. **Agent Answer Generation**: For each test question, the system uses Gemini to generate a realistic agent answer
2. **Comparison**: Gemini compares the agent's answer with the ground truth
3. **Status Assignment**: Based on the comparison, each test is marked as:
   - `PASS`: Answer is correct and matches ground truth intent
   - `FAIL`: Answer is incorrect or contradicts ground truth
   - `WARN`: Answer is partially correct or missing details

### 2. API Configuration
The Gemini API key is configured in `.env`:
```
GEMINI_API_KEY=AIzaSyAH-UEjrJTl1tK87do-g6BHz4H0CettvpA
```

### 3. Endpoint
**POST** `/api/v1/domains/{domain_id}/run-eval`

**Response:**
```json
{
  "status": "completed",
  "run_id": "uuid-here",
  "test_sets_evaluated": 5,
  "message": "Evaluation completed using Gemini API"
}
```

### 4. Test Set Data Structure
Each test set now includes:
- `question`: The test question
- `ground_truth`: Expected answer
- `difficulty`: easy/medium/hard
- `last_status`: pass/fail/warn
- `last_agent_answer`: The agent's generated answer
- `last_evaluation_reasoning`: Why the evaluation resulted in that status
- `last_run_id`: ID of the evaluation run

## Example Evaluation

**Question:** "What is the year-over-year growth rate for Q4?"

**Golden Answer:** "Calculate (Q4_2024_revenue - Q4_2023_revenue) / Q4_2023_revenue * 100"

**Agent Answer:** (Generated by Gemini)
"To calculate the year-over-year growth rate for Q4, we need to compare Q4 2024 revenue with Q4 2023 revenue using the formula: ((Current Period - Previous Period) / Previous Period) Ã— 100"

**Evaluation Result:**
- Status: PASS
- Reasoning: "The agent correctly identified the YoY growth formula and the periods to compare"

## Testing the System

1. Navigate to the Golden Test Set section in the frontend
2. Ensure you have test sets created (or run the seed script)
3. Click "Run Evaluation" button
4. Wait for the evaluation to complete
5. View the results with status indicators and reasoning

## Fallback Behavior
If the Gemini API key is not configured or there's an error:
- The system falls back to random status assignment
- An error message is logged
- The evaluation still completes but with mock data

## Dependencies
- `google-generativeai==0.8.3` (installed via requirements.txt)
- Valid Gemini API key in environment variables